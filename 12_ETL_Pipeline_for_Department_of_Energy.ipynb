{"cells":[{"source":"<center><img src=\"image.png\" width=500></center>\n<p>\n\nYou've recently started a new position as a Data Engineer at an energy company. Previously, analysts on other teams had to manually retrieve and clean data every quarter to understand changes in the sales and capability of different energy types. This process normally took days and was something that most analytsts dreaded. Your job is to automate this process by building a data pipeline. You'll write this data pipeline to pull data each month, helping to provide more rapid insights and free up time for your data consumers.\n\nYou will achieve this using the `pandas` library and its powerful parsing features. You'll be working with two raw files; `electricity_sales.csv` and `electricity_capability_nested.json`. \n    \nBelow, you'll find a data dictionary for the `electricity_sales.csv` dataset, which you'll be transforming in just a bit. Good luck!\n\n| Field | Data Type |\n| :---- | :-------: |\n| period  | `str`        |\n| stateid | `str` |\n| stateDescription | `str` |\n| sectorid | `str` |\n| sectorName | `str` |\n| price | `float` |\n| price-units | `str` |","metadata":{},"id":"a5693425-9491-4a0c-98e0-664cf6df248b","cell_type":"markdown"},{"source":"import pandas as pd\nimport json","metadata":{"executionCancelledAt":null,"executionTime":3594,"lastExecutedAt":1746718161730,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport json"},"id":"408b0fb1-926b-4c41-98e8-15803a1999cb","cell_type":"code","execution_count":1,"outputs":[]},{"source":"First, define an `extract_tabular_data()` function to ingest tabular data. This function will take a single parameter, `file_path`. If `file_path` ends with .csv, use the `pd.read_csv()` function to extract the data. If `file_path` ends with `.parquet`, use the `pd.read_parquet()` function to extract the data. Otherwise, raise an exception and print the message: \"Warning: Invalid file extension. Please try with .csv or .parquet!\".","metadata":{},"cell_type":"markdown","id":"342c428e-57b0-4ee7-9c1c-49ccba74043f"},{"source":"def extract_tabular_data(file_path: str):\n    \"\"\"Extract data from a tabular file_format, with pandas.\"\"\"\n    if file_path.endswith('.csv'): \n        return pd.read_csv(file_path)\n    elif file_path.endswith('.parquet'): \n        return pd.read_parquet(file_path)\n    else: \n        raise Exception(\"Warning: Invalid file extension. Please try with .csv or .parquet!\")","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1746718161782,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def extract_tabular_data(file_path: str):\n    \"\"\"Extract data from a tabular file_format, with pandas.\"\"\"\n    if file_path.endswith('.csv'): \n        return pd.read_csv(file_path)\n    elif file_path.endswith('.parquet'): \n        return pd.read_parquet(file_path)\n    else: \n        raise Exception(\"Warning: Invalid file extension. Please try with .csv or .parquet!\")"},"id":"e79342a8-2eeb-4bcc-92f0-70c5ebec76e5","cell_type":"code","execution_count":2,"outputs":[]},{"source":"Create another function with the name `extract_json_data()`, which takes a `file_path`. Use the `json_normalize()` function from the **pandas** library to flatten the nested JSON data, and return a pandas **DataFrame**.","metadata":{},"cell_type":"markdown","id":"1f15d58b-4180-4250-a1f5-5bf84dc316ff"},{"source":"def extract_json_data(file_path):\n    \"\"\"Extract and flatten data from a JSON file.\"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return pd.json_normalize(data)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1746718161830,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def extract_json_data(file_path):\n    \"\"\"Extract and flatten data from a JSON file.\"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    return pd.json_normalize(data)"},"id":"ecbc91c2-e0cc-4ae7-a7e8-ab2a56f1a1a9","cell_type":"code","execution_count":3,"outputs":[]},{"source":"Next, we'll need to build a function to transform the electricity sales data. To do that, we'll create a function called `transform_electricity_sales_data()` which takes a single parameter `raw_data`. `raw_data` should be of type **pd.DataFrame**. The `transform_electricity_sales_data()` needs to fullfil some requirements that are described below in the docstring following the function definition.","metadata":{},"cell_type":"markdown","id":"07198285-78e5-41de-948d-8a766ea0c20d"},{"source":"def transform_electricity_sales_data(raw_data: pd.DataFrame):\n    \"\"\"\n    Transform electricity sales to find the total amount of electricity sold\n    in the residential and transportation sectors.\n    \n    To transform the electricity sales data, you'll need to do the following:\n    - Drop any records with NA values in the `price` column. Do this inplace.\n    - Only keep records with a `sectorName` of \"residential\" or \"transportation\".\n    - Create a `month` column using the first 4 characters of the values in `period`.\n    - Create a `year` column using the last 2 characters of the values in `period`.\n    - Return the transformed `DataFrame`, keeping only the columns `year`, `month`, `stateid`, `price` and `price-units`.\n    \"\"\"\n    raw_data.dropna(subset=['price'], inplace=True)\n    filtered_data = raw_data[raw_data['sectorName'].isin(['residential', 'transportation'])].copy()\n    filtered_data['month'] = filtered_data['period'].str[:4]\n    filtered_data['year'] = filtered_data['period'].str[-2:]\n    return filtered_data[['year', 'month', 'stateid', 'price', 'price-units']]","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1746718161878,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def transform_electricity_sales_data(raw_data: pd.DataFrame):\n    \"\"\"\n    Transform electricity sales to find the total amount of electricity sold\n    in the residential and transportation sectors.\n    \n    To transform the electricity sales data, you'll need to do the following:\n    - Drop any records with NA values in the `price` column. Do this inplace.\n    - Only keep records with a `sectorName` of \"residential\" or \"transportation\".\n    - Create a `month` column using the first 4 characters of the values in `period`.\n    - Create a `year` column using the last 2 characters of the values in `period`.\n    - Return the transformed `DataFrame`, keeping only the columns `year`, `month`, `stateid`, `price` and `price-units`.\n    \"\"\"\n    raw_data.dropna(subset=['price'], inplace=True)\n    filtered_data = raw_data[raw_data['sectorName'].isin(['residential', 'transportation'])].copy()\n    filtered_data['month'] = filtered_data['period'].str[:4]\n    filtered_data['year'] = filtered_data['period'].str[-2:]\n    return filtered_data[['year', 'month', 'stateid', 'price', 'price-units']]"},"id":"3cc22273-22b8-4f30-8c11-a746f884509f","cell_type":"code","execution_count":4,"outputs":[]},{"source":"To load a DataFrame to a file, we'll define one more function called `load()`, which takes a DataFrame and a `file_path`. If the file_path ends with `.csv`, load the DataFrame to a CSV file. If instead the `file_path` ends with `.parquet`, load the DataFrame to a Parquet file. Otherwise, raise an exception that outputs a message in this format: \"Warning: {filepath} is not a valid file type. Please try again!_\"","metadata":{},"cell_type":"markdown","id":"29bc2d7c-093b-43c2-b554-210dd94bff72"},{"source":"def load(dataframe: pd.DataFrame, file_path: str):\n    \"\"\"Load a DataFrame to a file in either CSV or Parquet format.\"\"\"\n    if file_path.endswith('.csv'):\n        dataframe.to_csv(file_path, index=False)\n    elif file_path.endswith('.parquet'):\n        dataframe.to_parquet(file_path, index=False)\n    else:\n        raise Exception(f\"Warning: {file_path} is not a valid file type. Please try again.\")","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1746718161926,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def load(dataframe: pd.DataFrame, file_path: str):\n    \"\"\"Load a DataFrame to a file in either CSV or Parquet format.\"\"\"\n    if file_path.endswith('.csv'):\n        dataframe.to_csv(file_path, index=False)\n    elif file_path.endswith('.parquet'):\n        dataframe.to_parquet(file_path, index=False)\n    else:\n        raise Exception(f\"Warning: {file_path} is not a valid file type. Please try again.\")"},"id":"66e6db3c-ebfa-4f7b-9668-eac8a01f4263","cell_type":"code","execution_count":5,"outputs":[]},{"source":"# Ready for the moment of truth? It's time to test the functions that you wrote!\nraw_electricity_capability_df = extract_json_data(\"electricity_capability_nested.json\")\nraw_electricity_sales_df = extract_tabular_data(\"electricity_sales.csv\")    \n\ncleaned_electricity_sales_df = transform_electricity_sales_data(raw_electricity_sales_df)\n\nload(raw_electricity_capability_df, \"loaded__electricity_capability.parquet\")\nload(cleaned_electricity_sales_df, \"loaded__electricity_sales.csv\")","metadata":{"executionCancelledAt":null,"executionTime":137,"lastExecutedAt":1746718162064,"lastExecutedByKernel":"d9704a7e-b94b-4946-b7f3-6f208e1aa22d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Ready for the moment of truth? It's time to test the functions that you wrote!\nraw_electricity_capability_df = extract_json_data(\"electricity_capability_nested.json\")\nraw_electricity_sales_df = extract_tabular_data(\"electricity_sales.csv\")    \n\ncleaned_electricity_sales_df = transform_electricity_sales_data(raw_electricity_sales_df)\n\nload(raw_electricity_capability_df, \"loaded__electricity_capability.parquet\")\nload(cleaned_electricity_sales_df, \"loaded__electricity_sales.csv\")"},"id":"befd9c30-8fa0-465f-bfc4-675d25d51e62","cell_type":"code","execution_count":6,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}